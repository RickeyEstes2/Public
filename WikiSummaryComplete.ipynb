{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RickeyEstes2/Public/blob/main/WikiSummaryComplete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm really enjoying this course on Udemy and think you might like it too.\n",
        "https://www.udemy.com/share/104xGa3@Ll9jl5e5GcVJttkFyKapOxGfFgry6HrS_Dfmh8G6HEdqX2xXzdQJrcEW0Yuvb9T4ew==/"
      ],
      "metadata": {
        "id": "JqT3z3tg0TTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='#ffhh33'>Section 18\n",
        "###<font color='#aaaaaa'> -<b> Extraction-Based Summarization</b>"
      ],
      "metadata": {
        "id": "CA7VhQLY0Qzv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ob6Jc07nKjZ"
      },
      "source": [
        "##<font color=\"#fd79a8\">Extraction-Based Summarizer <br><font color=\"#48dbfb\">Scraped Wikipedia articles using Beautiful Soup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L80gVJiZ1fvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840057d7-90e5-4220-a656-3e6809c5e328"
      },
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "#persian cuisine\n",
        "#scraped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Iranian_cuisine')\n",
        "\n",
        "\n",
        "#scraped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Brain-computer_interface')\n",
        "scraped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/first_order_phase_transition')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "article = scraped_data.read()\n",
        "\n",
        "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
        "\n",
        "paragraphs = parsed_article.find_all('p')\n",
        "\n",
        "article_text = \"\"\n",
        "\n",
        "for p in paragraphs:\n",
        "    article_text += p.text"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_4EmP8l1tLi"
      },
      "source": [
        "# Removing Square Brackets and Extra Spaces\n",
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
        "#any whitespace character \\s+\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-AKwDkc15h6"
      },
      "source": [
        "# Removing special characters and digits\n",
        "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
        "#any whitespace character \\s+\n",
        "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3dlAgyRvLa4"
      },
      "source": [
        "##<font color=\"#fd79a8\">Convert paragraphs to sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1BxJpQx15ss"
      },
      "source": [
        "sentence_list = nltk.sent_tokenize(article_text)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGWRc5NY2g8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf469866-d867-4d1e-d872-d42cc3b03d29"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ-LlCwBwE7J"
      },
      "source": [
        "###<font color=\"#fd79a8\"> Loop to calculate the word frequencies. <br>Tokenize the sentences<br>if word is not a stopword and is in the word list, the count is added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA4mWOgK2X6Y"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(formatted_article_text):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4v06sl2xA_v"
      },
      "source": [
        "###<font color=\"#48dbfb\"> Keys() method<br>The keys() method returns a view object. The view object contains the keys of the dictionary, as a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u70SSN1cxO2i",
        "outputId": "d0ae470a-aeb5-423b-f116-ad219f7f4939"
      },
      "source": [
        "shoe = {\n",
        "  \"brand\": \"Nike\",\n",
        "  \"series\": \"Air Max\",\n",
        "  \"price\": 100\n",
        "}\n",
        "\n",
        "var = shoe.keys()\n",
        "\n",
        "print(var)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['brand', 'series', 'price'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOPnTZ9ixUvl"
      },
      "source": [
        "###<font color=\"#48dbfb\">When an item is added in the dictionary, the view object also gets updated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5rYePFbxSd0",
        "outputId": "c51fd593-1eff-4c21-eedb-7dab266f3a6e"
      },
      "source": [
        "shoe[\"color\"] = \"red\"\n",
        "\n",
        "print(var)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['brand', 'series', 'price', 'color'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzSatUTS8WK7"
      },
      "source": [
        "###<font color=\"#48dbfb\">Find weighted frequency of occurence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D34gqm-42lBq"
      },
      "source": [
        "maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw5PmlZHycfs",
        "outputId": "570ae004-549b-425b-d749-552e1bb3676e"
      },
      "source": [
        "shoe = {\n",
        "  \"brand\": \"Nike\",\n",
        "  \"series\": \"Air Max\",\n",
        "  \"price\": 100\n",
        "}\n",
        "\n",
        "var = shoe.values()\n",
        "\n",
        "print(var)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values(['Nike', 'Air Max', 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2LMj2pa8L0k"
      },
      "source": [
        "###<font color=\"#48dbfb\">Replace words with weighted frequency in sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNUVxbcD2lOD"
      },
      "source": [
        "sentence_scores = {}\n",
        "for sent in sentence_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0mMnhCX8lLJ"
      },
      "source": [
        "####<font color=\"#fd79a8\">Heap queue <br>heap queue algorithm, also known as the priority queue algorithm<br>It makes it possible to view the data (words/scores) -  our heap, as a regular Python list<br><font color=\"#0abde3\">heapq.nlargest(n, iterable, key=None)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThhA39562rxN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "e1431447-7852-4988-955a-6089cf9df8b1"
      },
      "source": [
        "import heapq\n",
        "summary_sentences = heapq.nlargest(10, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "summary = ' '.join(summary_sentences)\n",
        "summary"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Examples include: quantum phase transitions, dynamic phase transitions, and topological (structural) phase transitions.  In chemistry, thermodynamics, and other related fields, a phase transition (or phase change) is the physical process of transition between one state of a medium and another. In the modern classification scheme, phase transitions are divided into two broad categories, named similarly to the Ehrenfest classes: First-order phase transitions are those that involve a latent heat. For example, the Gross–Witten–Wadia phase transition in 2-d lattice quantum chromodynamics is a third-order phase transition. Second-order phase transitions are also called \"continuous phase transitions\". Other phase changes include: Phase transitions occur when the thermodynamic free energy of a system is non-analytic for some choice of thermodynamic variables (cf. As with states of matter, there are also a metastable to equilibrium phase transformation for structural phase transitions. Apart from isolated, simple phase transitions, there exist transition lines as well as multicritical points, when varying external parameters like the magnetic field or composition. There are also a number of phase transitions involving three phases: a eutectic transformation, in which a two-component single-phase liquid is cooled and transforms into two solid phases. First reported in the case of a ferromagnetic to anti-ferromagnetic transition, such persistent phase coexistence has now been reported across a variety of first-order magnetic transitions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open('example7777.txt', 'w') as f:\n",
        "  f.write(summary)\n",
        "\n",
        "files.download('example7777.txt')"
      ],
      "metadata": {
        "id": "jvxmLdMQinVm",
        "outputId": "9abf47c4-231d-439e-db09-6eaad88c4f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cee53ea5-b361-4200-9380-03a4a52070c4\", \"example7777.txt\", 1556)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}