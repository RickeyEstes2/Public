{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RickeyEstes2/Public/blob/main/WikiSummaryLecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJjf7znUPxUD"
      },
      "source": [
        "##<font color=\"#fd79a8\">Extraction-Based Summarizer <br><font color=\"#48dbfb\">Scraped Wikipedia articles using Beautiful Soup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuFXEmqaBnpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dee61e6-045f-4590-c532-27fbda235bf9"
      },
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_wiki = urllib.request.urlopen('https://en.wikipedia.org/wiki/Iranian_cuisine')\n",
        "wiki = scraped_wiki.read()\n",
        "\n",
        "parse_wiki = bs.BeautifulSoup(wiki, \"lxml\")\n",
        "article_para = parse_wiki.find_all('p')\n",
        "\n",
        "text = ''\n",
        "\n"
      ],
      "metadata": {
        "id": "Xy_8fBAoHglh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-CPkr4jXczK"
      },
      "source": [
        "####<font color=\"#fd79a8\"> Cleaning on the Text data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = re.sub(r'\\[[0-9]*\\]', ' ', text)\n",
        "text = re.sub(r'\\s', ' ', text)\n",
        "new_text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "new_text = re.sub(r'\\s', ' ', new_text)"
      ],
      "metadata": {
        "id": "csAtxqyGKMbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''\n",
        "\n",
        "for p in article_para:\n",
        "  text += p.text\n"
      ],
      "metadata": {
        "id": "iLoreI-Fk2Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3dlAgyRvLa4"
      },
      "source": [
        "##<font color=\"#fd79a8\">Convert paragraphs to sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGWRc5NY2g8J"
      },
      "source": [
        "sentences = nltk.sent_tokenize(new_text)\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ-LlCwBwE7J"
      },
      "source": [
        "###<font color=\"#fd79a8\"> Loop to calculate the word frequencies. <br>Tokenize the sentences<br>if word is not a stopword and is in the word list, the count is added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA4mWOgK2X6Y"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "token_freq = {}\n",
        "\n",
        "for token in nltk.word_tokenize(new_text):\n",
        "  if token not in stopwords:\n",
        "    if token not in token_freq.keys():\n",
        "      token_freq(token) = 1\n",
        "    else:\n",
        "      token_freq(token) += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4v06sl2xA_v"
      },
      "source": [
        "###<font color=\"#48dbfb\"> Keys() method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u70SSN1cxO2i"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOPnTZ9ixUvl"
      },
      "source": [
        "###<font color=\"#48dbfb\">When an item is added in the dictionary, the view object also gets updated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5rYePFbxSd0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOzXIvRDecP7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDWo1ja-ecmf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzSatUTS8WK7"
      },
      "source": [
        "###<font color=\"#48dbfb\">Find weighted frequency of occurence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D34gqm-42lBq"
      },
      "source": [
        "max_freq = max(token_freq.values())\n",
        "\n",
        "for token in token_freq.keys():\n",
        "  token_freq(token) = (token_freq([token]/max_freq))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw5PmlZHycfs"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2LMj2pa8L0k"
      },
      "source": [
        "###<font color=\"#48dbfb\">Replace words with weighted frequency in sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNUVxbcD2lOD"
      },
      "source": [
        "weight = {}\n",
        "\n",
        "for sent in sentences:\n",
        "  for token in nltk.word_tokenize(sent.lower()):\n",
        "    if token in token_freq.keys():\n",
        "      if len(sent.split(' ')) < 30:\n",
        "        if sent not in weight.keys():\n",
        "          weight[sent] = token_freq[token]\n",
        "        else:\n",
        "          weight[sent] += token_freq[token]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0mMnhCX8lLJ"
      },
      "source": [
        "####<font color=\"#fd79a8\">Heap queue <br>It makes it possible to view the data (words/scores) -  our heap, as a regular Python list<br><font color=\"#0abde3\">heapq.nlargest(n, iterable, key=None)"
      ]
    }
  ]
}