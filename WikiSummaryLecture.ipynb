{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RickeyEstes2/Public/blob/main/WikiSummaryLecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJjf7znUPxUD"
      },
      "source": [
        "##<font color=\"#fd79a8\">Extraction-Based Summarizer <br><font color=\"#48dbfb\">Scraped Wikipedia articles using Beautiful Soup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuFXEmqaBnpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d092aa7-601e-4a15-ba8f-dfe7aed4b4cd"
      },
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_wiki = urllib.request.urlopen('https://en.wikipedia.org/wiki/Iranian_cuisine')\n",
        "wiki = scraped_wiki.read()\n",
        "\n",
        "parse_wiki = bs.BeautifulSoup(wiki, \"lxml\")\n",
        "article_para = parse_wiki.find_all('p')\n",
        "\n",
        "text = ''\n",
        "\n"
      ],
      "metadata": {
        "id": "Xy_8fBAoHglh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-CPkr4jXczK"
      },
      "source": [
        "####<font color=\"#fd79a8\"> Cleaning on the Text data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = re.sub(r'\\[[0-9]*\\]', ' ', text)\n",
        "text = re.sub(r'\\s', ' ', text)\n",
        "new_text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "new_text = re.sub(r'\\s', ' ', new_text)"
      ],
      "metadata": {
        "id": "csAtxqyGKMbH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''\n",
        "\n",
        "for p in article_para:\n",
        "  text += p.text\n"
      ],
      "metadata": {
        "id": "iLoreI-Fk2Ze"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3dlAgyRvLa4"
      },
      "source": [
        "##<font color=\"#fd79a8\">Convert paragraphs to sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGWRc5NY2g8J",
        "outputId": "3657570b-c563-43c4-96aa-fad793f7b632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentences = nltk.sent_tokenize(new_text)\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ-LlCwBwE7J"
      },
      "source": [
        "###<font color=\"#fd79a8\"> Loop to calculate the word frequencies. <br>Tokenize the sentences<br>if word is not a stopword and is in the word list, the count is added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA4mWOgK2X6Y"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "token_freq = {}\n",
        "\n",
        "for token in nltk.word_tokenize(new_text):\n",
        "  if token not in stopwords:\n",
        "    if token not in token_freq.keys():\n",
        "      token_freq[token] = 1\n",
        "    else:\n",
        "      token_freq[token] += 1\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4v06sl2xA_v"
      },
      "source": [
        "###<font color=\"#48dbfb\"> Keys() method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u70SSN1cxO2i"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOPnTZ9ixUvl"
      },
      "source": [
        "###<font color=\"#48dbfb\">When an item is added in the dictionary, the view object also gets updated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5rYePFbxSd0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOzXIvRDecP7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDWo1ja-ecmf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzSatUTS8WK7"
      },
      "source": [
        "###<font color=\"#48dbfb\">Find weighted frequency of occurence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D34gqm-42lBq",
        "outputId": "2106b9b8-de00-4318-c975-68abfb7a2034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "max_freq = max(token_freq.values())\n",
        "\n",
        "for token in token_freq.keys():\n",
        "  token_freq[token] = (token_freq([token]/max_freq))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0f6f4045ec2d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_freq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_freq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtoken_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw5PmlZHycfs"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2LMj2pa8L0k"
      },
      "source": [
        "###<font color=\"#48dbfb\">Replace words with weighted frequency in sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNUVxbcD2lOD"
      },
      "source": [
        "weight = {}\n",
        "\n",
        "for sent in sentences:\n",
        "  for token in nltk.word_tokenize(sent.lower()):\n",
        "    if token in token_freq.keys():\n",
        "      if len(sent.split(' ')) < 30:\n",
        "        if sent not in weight.keys():\n",
        "          weight[sent] = token_freq[token]\n",
        "        else:\n",
        "          weight[sent] += token_freq[token]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0mMnhCX8lLJ"
      },
      "source": [
        "####<font color=\"#fd79a8\">Heap queue <br>It makes it possible to view the data (words/scores) -  our heap, as a regular Python list<br><font color=\"#0abde3\">heapq.nlargest(n, iterable, key=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "extracted_sentences = heapq.nlargest(5, weight, key=weight.get)\n",
        "summary = ' '.join(extracted_sentences)\n",
        "summary\n"
      ],
      "metadata": {
        "id": "mePN2QXKU-VK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}